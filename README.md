# Sales Management System - Master-Slave PostgreSQL Implementation

This repository provides a comprehensive implementation of a **Sales Management System** using **PostgreSQL master-slave replication** with **Change Data Capture (CDC)** and **RisingWave**. The system demonstrates real-world clean architecture patterns with a modern **Streamlit** dashboard for data management and analytics.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Streamlit Dashboard                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Data Management   â”‚  â”‚     Analytics Dashboard        â”‚   â”‚
â”‚  â”‚   (CRUD Operations) â”‚  â”‚     (Real-time Reports)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Services Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Sales Service (Business Logic)                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Repository Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Sales Repository (Data Access)                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Database Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Master Database    â”‚    â”‚      Slave Database          â”‚   â”‚
â”‚  â”‚   (Write Operations) â”‚â—„â”€â”€â–ºâ”‚    (Read Operations)         â”‚   â”‚
â”‚  â”‚   - INSERT           â”‚    â”‚    - SELECT                  â”‚   â”‚
â”‚  â”‚   - UPDATE           â”‚    â”‚    - Analytics Queries       â”‚   â”‚
â”‚  â”‚   - DELETE           â”‚    â”‚                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

### Core Features

- **Master-Slave Database Pattern**: Write operations go to master, read operations from slave
- **Clean Architecture**: Separation of concerns with proper layering
- **Real-time Analytics**: Live dashboard with sales metrics and trends
- **CRUD Operations**: Complete Create, Read, Update, Delete functionality
- **Data Validation**: Comprehensive input validation and error handling
- **Sample Data Generation**: Built-in fake data generator for testing

### Dashboard Features

- **ğŸ“Š Data Management Interface**

  - View transactions and sales items
  - Add new transactions with multiple items
  - Edit existing transactions and items
  - Delete operations with confirmation
  - Paginated data display

- **ğŸ“ˆ Analytics Dashboard**
  - Key performance metrics (revenue, transactions, items sold)
  - Sales trend charts (daily revenue over time)
  - Top products analysis
  - Recent transactions overview
  - Interactive Plotly charts

### Technical Features

- **Containerized Database**: Docker setup for PostgreSQL master-slave
- **Connection Pooling**: Efficient database connection management
- **Error Handling**: Comprehensive error handling and logging
- **Environment Configuration**: Flexible configuration via environment variables
- **Type Safety**: Pydantic models for data validation

## ğŸ“¦ Project Structure

```
src/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py           # Application configuration
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ manager.py            # Database connection manager
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ sales.py              # Pydantic data models
â”œâ”€â”€ repositories/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ interfaces.py         # Repository interfaces
â”‚   â””â”€â”€ sales_repository.py   # Sales data access layer
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ sales_service.py      # Business logic layer
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ .streamlit/
â”‚   â”‚   â””â”€â”€ config.toml       # Streamlit configuration
â”‚   â””â”€â”€ main.py               # Streamlit dashboard
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ helpers.py            # Utility functions
â”‚   â””â”€â”€ sample_data.py        # Sample data generator
â”œâ”€â”€ main.py                   # Application entry point
â””â”€â”€ requirements.txt          # Python dependencies
```

## ğŸ—„ï¸ Database Schema

The system uses two main tables for sales transaction management:

### Sales Transaction Table

```sql
CREATE TABLE sales_transaction (
    transaction_id SERIAL PRIMARY KEY,
    transaction_time TIMESTAMP NOT NULL,
    cashier_id INT NOT NULL,
    store_id INT NOT NULL,
    payment_method VARCHAR(50) NOT NULL,
    total_amount NUMERIC(12, 2) NOT NULL,
    total_discount NUMERIC(12, 2) DEFAULT 0,
    customer_id INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Sales Item Table

```sql
CREATE TABLE sales_item (
    item_id SERIAL PRIMARY KEY,
    transaction_id INT REFERENCES sales_transaction(transaction_id) ON DELETE CASCADE,
    product_code VARCHAR(50) NOT NULL,
    product_name VARCHAR(255) NOT NULL,
    category VARCHAR(100),
    quantity INT NOT NULL,
    unit_price NUMERIC(10, 2) NOT NULL,
    discount NUMERIC(10, 2) DEFAULT 0,
    total_price NUMERIC(12, 2) NOT NULL
);
```

## âš™ï¸ Installation & Setup

### Prerequisites

- Python 3.8+
- Docker & Docker Compose
- Git

## âš¡ Super Quick Start (1 Command)

```bash
python setup.py
```

This single command will:

- âœ… Check Docker installation
- âœ… Start PostgreSQL master-slave databases
- âœ… Install Python dependencies
- âœ… Launch the Streamlit application

---

## âš¡ Quick Start (Simple Way)

### Prerequisites

- Python 3.8+
- Docker & Docker Compose

### 3 Simple Steps to Run

1. **Start Database Services**

   ```bash
   docker-compose up -d postgres-master postgres-slave
   ```

2. **Navigate to Source Directory**

   ```bash
   cd src
   ```

3. **Run the Application**

   ```bash
   python run.py
   ```

   The script will:

   - Automatically check and install missing dependencies
   - Initialize the database tables
   - Start the Streamlit application at `http://localhost:8501`

### Alternative Direct Method

```bash
# Install dependencies manually (if needed)
pip install -r src/requirements.txt

# Run the main application
cd src
streamlit run main.py
```

## ğŸ“¦ What's Included

The complete system is contained in a **single main.py file** (1000+ lines) that includes:

- Database connection management (master-slave pattern)
- Data models and validation
- Business logic services
- Complete Streamlit web interface
- Sample data generator
- Real-time analytics dashboard

## ğŸ”§ Simple Configuration

Database connections can be configured via environment variables in `.env`:

```bash
# Master Database (Write Operations)
MASTER_DB_HOST=localhost
MASTER_DB_PORT=5676
MASTER_DB_USER=postgres
MASTER_DB_PASSWORD=postgres

# Slave Database (Read Operations)
SLAVE_DB_HOST=localhost
SLAVE_DB_PORT=5677
SLAVE_DB_USER=postgres
SLAVE_DB_PASSWORD=postgres
```

## ğŸ¯ Usage Examples

### Adding a New Transaction

1. Navigate to "Data Management" â†’ "Add Transaction"
2. Fill in transaction details (cashier ID, store ID, payment method)
3. Add one or more items with product details
4. Click "Create Transaction"

### Viewing Analytics

1. Navigate to "Analytics Dashboard"
2. View key metrics (total revenue, transactions, items sold)
3. Analyze sales trends and top products
4. Check recent transaction activity

### Master-Slave Verification

The system automatically routes:

- **Write operations** (INSERT, UPDATE, DELETE) â†’ Master Database
- **Read operations** (SELECT, Analytics) â†’ Slave Database

## ğŸ” Key Components

### Database Manager (`database/manager.py`)

- Manages connection pools for master and slave databases
- Provides context managers for safe connection handling
- Implements read/write operation routing

### Sales Service (`services/sales_service.py`)

- Contains business logic for sales operations
- Handles transaction calculations and validations
- Provides high-level API for the presentation layer

### Sales Repository (`repositories/sales_repository.py`)

- Implements data access patterns
- Executes SQL queries with proper parameter binding
- Handles database-specific operations

### Streamlit Dashboard (`streamlit_app/main.py`)

- Modern web interface for data management
- Interactive charts and visualizations
- Real-time data updates and form handling

## ğŸ§ª Testing with Sample Data

The system includes a built-in sample data generator that creates realistic sales transactions:

```python
# Generate 20 sample transactions
python main.py sample-data
```

Sample data includes:

- Realistic product names and categories (coffee, food, desserts)
- Random transaction times within the last 30 days
- Various payment methods
- Multiple items per transaction
- Proper price calculations with discounts

## ğŸ³ Docker Services

The `docker-compose.yml` includes:

- **postgres-master**: Master database (port 5676)
- **postgres-slave**: Slave database (port 5677)
- **RisingWave components**: For CDC and stream processing
- **Prometheus**: For monitoring and metrics
- **MinIO**: For object storage

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support

If you encounter any issues or have questions:

1. Check the troubleshooting section below
2. Open an issue on GitHub
3. Review the logs in `app.log`

## ğŸ”§ Troubleshooting

### Database Connection Issues

```bash
# Check if Docker services are running
docker-compose ps

# Restart database services
./run.sh stop
./run.sh docker

# Check database logs
docker-compose logs postgres-master
docker-compose logs postgres-slave
```

### Python Dependencies Issues

```bash
# Recreate virtual environment
./run.sh clean
./run.sh setup
```

### Port Conflicts

If ports 5676, 5677, or 8501 are in use, modify the `.env` file or `docker-compose.yml` accordingly.

---

**Built with â¤ï¸ using Python, PostgreSQL, Streamlit, and Docker**
